#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\options openright
\use_default_options false
\master ../thesis.lyx
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Indice
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language french
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
In this chapter we propose an approach based on a traditional database (RDBMS
 database), we use this approach to compare the performance of CS-NoSQL
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Performance-Evaluation"

\end_inset

.
 Of course, except for the database, we try to emulate the approaches of
 CS-NoSQL.
 The architecture proposed could be implemented with any RDBMS that has
 an advanced trigger support.
 In fact even if in some cases we use a proprietary solution, an alternative
 (general) solution is provided.
\end_layout

\begin_layout Standard
Firstly we show and explain all the base technologies to explain the architectur
e in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Technologies-traditional"

\end_inset

: PostgreSQL, redis and socket.io.
\begin_inset Newline newline
\end_inset

Then we explain the architecture proposed that is general in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Architecture-traditional"

\end_inset

, it is composed by different parts: database, publish/subscribe, websocket
 server, input server and custom logic.
 We explain how to implement each part of the architecture using the technologie
s explained before.
\begin_inset Newline newline
\end_inset

Finally we show our implementation in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Implementation"

\end_inset

, explain better some logic parts that depend on the implementation not
 on the theoretical concepts: server logic and client logic.
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Technologies-traditional"

\end_inset

Technologies Background
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:PostgreeSQL"

\end_inset

PostgreSQL
\end_layout

\begin_layout Standard
The RDBS are CA according to the CAP theorem and as shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:-Database-triangle"

\end_inset

, i.e.
 they do not support a partition of data in an efficient way.
 But of course they can be partitioned.
\series bold

\begin_inset Newline newline
\end_inset


\series default
Moreover they can be replicated according to the structures explained in
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Multi-Master-&-Master-Slaves"

\end_inset

: multi master or master-slaves.
\begin_inset Newline newline
\end_inset

PostgreSQL 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://www.postgresql.org/
\end_layout

\end_inset


\end_layout

\end_inset

 is a powerful and used database (so a lot of libraries are implemented).
 It can be partitioned 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgrePartitioning"

\end_inset

 and replicated in a multi-master architecture (and so also master-slaves)
 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreReplication"

\end_inset

.
\end_layout

\begin_layout Standard
Moreover it has interesting characteristics that we  use in the next sections:
 it is a very flexible database that allows using custom languages 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreLanguages"

\end_inset

, one of them is PL/sh 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/petere/plsh
\end_layout

\end_inset


\end_layout

\end_inset

 a language that allows executing shell commands, so we are able to call
 an external program and it has a feature to create easily a sort of publish/sub
scribe system, it is a queue where you can publish messages and read them
 in order, to do that NOTIFY 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreNotify"

\end_inset

 and LISTEN 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreListen"

\end_inset

 commands are used.
 NOTIFY is really called only after the transaction is committed.
 Furthermore PostgreSQL has JSON as data type
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreJSON"

\end_inset

, it could be useful but we do not use it to keep the approach standard.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Redis"

\end_inset

Redis
\end_layout

\begin_layout Standard
Redis 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://redis.io/
\end_layout

\end_inset


\end_layout

\end_inset

 is a key-value storage in memory 
\begin_inset CommandInset citation
LatexCommand cite
key "CAPNoSQL"

\end_inset

, data can be written to the disk every fixed amount of time.
 It allows implementing a lot of different elements: cache system 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisCache"

\end_inset

, publish/subscribe system 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisPUBSUB"

\end_inset

, queue system using lists 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisQueue,RedisDataTypes"

\end_inset

 and distributed lock system that can be used by external systems 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisLock"

\end_inset

.
\begin_inset Newline newline
\end_inset

And has interesting features such as data partitioning support 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisPartitioning"

\end_inset

 or master-slaves replication support 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisReplication"

\end_inset

.
 Moreover everything (image, text, json and so on) can be inserted as the
 value (key-value storage), with a high storage limit (512 megabyte per
 value) 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisDataTypes"

\end_inset

.
\begin_inset Newline newline
\end_inset

Unfortunately to keep a high performance data are not stored immediately
 in the disk, but they are written every one second (default configuration)
 
\begin_inset CommandInset citation
LatexCommand cite
key "RedisPersistance"

\end_inset

.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Socket.io-architecture"

\end_inset

Socket.io
\end_layout

\begin_layout Standard
Socket.io 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://socket.io/
\end_layout

\end_inset


\end_layout

\end_inset

 is one of the most famous websocket servers, written in javascript.
 It is built on top of engine.io 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/socketio/engine.io
\end_layout

\end_inset


\end_layout

\end_inset

 that is like the transportation level in the ISO/OSI stack, it is very
 efficient but it is only a websocket implementation.
 As we  show socket.io has a lot of integrations and a native implementation
 (since the protocol is open 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOProtocol"

\end_inset

) that makes it the best choice for our tests.
 Furthermore it is the best open source websocket server 
\begin_inset CommandInset citation
LatexCommand cite
key "WebsocketServersComparison"

\end_inset

.
\begin_inset Newline newline
\end_inset

Socket.io has useful features for our application such as redis integration
 to create websocket cluster 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIORedis"

\end_inset

, user/session support 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOUsers"

\end_inset

, P2P support 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOP2P"

\end_inset

 that could be useful to implement a system like gun.js.
 Moreover messages are sent in FIFO order, it is an important property to
 have eventual consistency as we  show in the next sections.
\begin_inset Newline newline
\end_inset

Furthermore Socket.io allows emiting events to all the subscribed clients
 to that event 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOEmitEvent"

\end_inset

, so events are channels of a publish/subscribe system, also the client
 can send events that, generally, are caught only by the server, of course,
 since it is publish/subscribe, there is no notification of successfully
 delivery to the server (ack).
 So the approach to be used to work with it is the event driven approach.
 So we can a have a distributed publish/subscribe with user/session support.
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Architecture-traditional"

\end_inset

Architecture Proposed
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/traditional_architecture.png
	width 70col%
	clip

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Traditional-Architecture-propose"

\end_inset

Traditional Architecture Proposed
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In figure 
\series bold

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Traditional-Architecture-propose"

\end_inset


\series default
 we can observe the architecture proposed, every part is explained in the
 following sections.
\begin_inset Newline newline
\end_inset

We have also added an additional level: load balancer/CDN (content delivery
 network).
 Load balancer is used to scale 
\begin_inset CommandInset citation
LatexCommand cite
key "RFCCN,CDNBook"

\end_inset

, to route users to different socket.io servers.
\begin_inset Newline newline
\end_inset

In fact as we  observe in the architecture that we propose we can have more
 than one socket.io server, but there is no system to route users.
\begin_inset Newline newline
\end_inset

Since we do not need it in the tests phase, we skip this level to avoid
 inserting other levels to test.
\begin_inset Newline newline
\end_inset

As we  see in 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Benchmarks-strategy"

\end_inset

 we do not partition postgreSQL and redis, in fact there are not the bottleneck
 and we want to test only the realtime feature.
 In that way we keep things more simple, since we do not have also to consider
 the issues related to partitioning such as latency.
\end_layout

\begin_layout Standard
While a CS-NoSQL offers a full stack solution (often with client local database
 support) here we have to define every aspect of the stack.
 So we need to implement what we have defined in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Realtime-retrieve"

\end_inset

, client best practices, related needed aspects and what can be useful to
 emulate CS-NoSQL approach.
\begin_inset Newline newline
\end_inset

We implement a RDBMS database that must be scalable among nodes and triggers
 support to notify change, publish/subscribe system to publish notifications
 of changes, websocket server, input server where receiving data to be sent
 to the database, custom logic level an eventual level where to introduce
 custom logic and client framework/libraries to communicate to the server
 (cluster).
 In this solution we have a data granularity at a row level, since detailed
 granularity is not required by the further study that we  do.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Database-architecture-traditional"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:Database"

\end_inset

Database
\end_layout

\begin_layout Standard
We use postgreSQL So the normal operations are guaranteed by it (it has
 good libraries), so the consistency is guaranteed by it.
\begin_inset Newline newline
\end_inset

So the only thing we have to solve is the notifications of changes to an
 external system (a publish/subscribe system).
\begin_inset Newline newline
\end_inset

The trivial solution (and general) is a trigger that calls an external program
 (that publishes data on publish/subscribe system), this can be done easily
 using PL/sh as shown in appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:PostgreSQL-realtime-retrieve"

\end_inset

.
 But the call to an external program is not so efficient (startup time),
 moreover we should find a way to call the external program only after the
 commit.
\begin_inset Newline newline
\end_inset

So we can use another solution that is more efficient but not standard:
 PUBLISH/NOTIFY.
 The trigger publishes the message, then an external listener republishes
 them in the other publish/subscribe system.
\end_layout

\begin_layout Standard
We have the following steps when there is a change: trigger call publishes
 on a predefined postgreSQL channel for each event then a javascript listener
 listens to the same postgreSQL channel finally the javascript listener
 republishes the same message on publish/subscribe system setting also namespace
 and rooms.
 There are a lot of examples useful for our use case, one of them (with
 javascript listener) 
\begin_inset CommandInset citation
LatexCommand cite
key "PostgreNotifyListenExample"

\end_inset

 was modified and used in our final configuration published on github, we
 can observe that this approach is like a key-value approach.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Websocket-server-architecture-traditional"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:Websocket-Server"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:Publish/Subscribe-architecture-traditional"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:traditional-Publish/Subscribe"

\end_inset

Publish/Subscribe and Websocket server
\end_layout

\begin_layout Standard
We try to emulate the approach used in CS-NoSQL.
\begin_inset Newline newline
\end_inset

We use socket.io for websocket server.
 As previously said socket.io is a system built on top of the websocket system
 (engine.io), so the publish/subscribe broker server and the websocket server
 are in the same machine.
\begin_inset Newline newline
\end_inset

It implements a distributed (via redis) publish/subscribe, i.e.
 different publish/subscribe broker servers communicate through redis.
 But in this way we do not know the status of the entire network, we do
 not know which brokers are connected.
\begin_inset Newline newline
\end_inset

When a message is published on a broker server this replicates it on redis,
 then other broker servers read it and send it to the subscribed clients.
 So the listener script previously described when publishes something simply
 writes it on redis (without calling any broker server) 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOEmiter"

\end_inset

.
\begin_inset Newline newline
\end_inset

Everything is done automatically without custom configurations on broker
 server: every event (channel) used by the listener can be subscribed by
 the users.
\end_layout

\begin_layout Standard
Socket.io allows managing channels at high level, we can use: namespaces
 
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOChannels"

\end_inset

, we can use them to distinguish different tables, so we have the same events
 identified unequivocally for different tables and rooms
\begin_inset CommandInset citation
LatexCommand cite
key "SocketIOChannels"

\end_inset

, we can use them to create a sort of subchannel, a client could be subscribed
 only to one room that contains only events related only to some rows.
 Rooms can be very useful to set up permissions at a row level, of course
 a client can write and read only rooms where he is subscribed and only
 the server can subscribe it to rooms, so to do that a custom logic is needed.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Input-Server-architecture-traditional"

\end_inset

Input server
\end_layout

\begin_layout Standard
A good approach is to use RESTful to communications that do not need to
 be realtime events (they are synchronous requests).
\begin_inset Newline newline
\end_inset

But for simplicity we can send also the data form client to servers using
 websocket.
 Using socket.io also the client uses events approach that does not provide
 a successful delivery notification system, of course we can develop our
 system but for the tests that we have to do this (ack of actions done by
 the client) is not important.
\begin_inset Newline newline
\end_inset

So for every socket.io event the server calls actions on postgreSQL server,
 we  insert this logic into the custom logic.
\begin_inset Newline newline
\end_inset

The important thing of this approach is that the writes do not depend on
 redis (that has persistence problems) and the consistency of data is managed
 by postgreSQL.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Custom-Logic-architecture-traditional"

\end_inset

Custom logic
\end_layout

\begin_layout Standard
With socket.io we can insert a custom logic for events sent by the client,
 a simple example is shown in appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Custom-logic-appendix"

\end_inset

.
 But we cannot modify events generated by others, in that case the socket.io
 server acts only like a switch of messages, i.e.
 in a socket.io node we cannot modify messages sent by postgreSQL listener.
\begin_inset Newline newline
\end_inset

The two main operations to do in this level are: send data to database,
 we can define different events for different database operations and for
 each of them mapping the event with the database library method and manage
 subscriptions to rooms, this depends on the role of rooms.
 But if we use them for authorizations a simple solution is catching an
 event (sent by client) auth where we subscribe that client only to some
 rows based on the authentication result.
 For example we can subscribe (join to a room) the client only to rows that
 he owns (i.e.
 owner_id field matching).
\end_layout

\begin_layout Standard
The only problem with this solution is that there is no persistence of data
 associated to a client.
 If the socket.io server dies, if the client changes the server (if we have
 load balance organization) or if the connection is interrupted (and then
 reestablished) data associated to a client are lost.
\begin_inset Newline newline
\end_inset

The only critical thing in our approach is the authentication, in fact if
 we are able to identify the client we can store other elements (like rooms
 joined) in other places.
 A simple and standard approach, that is not centralized (so it does not
 need persistence), to authenticate clients is JWT (Json Web Token) 
\begin_inset CommandInset citation
LatexCommand cite
key "JWT"

\end_inset

.
 Eventually a resynchronization of data is needed (for messages lost during
 the down) but even if we do not implement it the solution remains eventual
 consistency.
 
\begin_inset Newline newline
\end_inset

Of course for the topic of the thesis it is not needed to develop this,
 in fact we need just to test performances as shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Benchmarks-strategy"

\end_inset

.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Client-library-and-architecture-traditional"

\end_inset

Client library and Local database
\end_layout

\begin_layout Standard
We have to create a local database that is the final interface of our client.
 So the client contacts only it, the local database sends data through websocket
 and receives notifications of changes through websocket as we said previously.
\begin_inset Newline newline
\end_inset

We use Last Writer Win to implement local database, so the replication should
 be eventual consistency.
 
\begin_inset Newline newline
\end_inset

So a local database implementation is an object that contains data and provides
 the read/write methods for the user.
\begin_inset Newline newline
\end_inset

We have the following situations: user calls write/update, local data are
 updated, at the same time the local database tries to update the remote
 servers until there are no network errors and data are updated by the server,
 a callback is called and it updates local data.
\end_layout

\begin_layout Standard
Often data are modified by the server: default values, data updated by triggers,
 constraints, id auto generated and so on.
 Since we write data on the client database we have to implement all of
 them in the client, but to do that we have to create a sort of SQL interpreter
 on the client.
 Of course if there are no network problems the issue could be solved waiting
 for the answer of the server, but this means to make the application not
 optimistic.
\begin_inset Newline newline
\end_inset

This issue is solved by other systems in the following ways (some of them
 are already implemented since they are NoSQL): simplify constraints (the
 client can replicate them easily), simplify defaults (the client can replicate
 them easily), no triggers, unique ID that can be generated by the client.
 For our application and tests we can skip everything except for ID, to
 solve it we can use a UUID (Universally Unique Identifier) 
\begin_inset CommandInset citation
LatexCommand cite
key "UUID"

\end_inset

 that can be easily generated by the client, socket.io server and postgreSQL
 server.
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Implementation"

\end_inset

Implementation
\end_layout

\begin_layout Standard
We tried to use Ecmascript where it is possible, using event driven approach.
 On github 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/carduz/master-thesis-source/tree/master/proposed_solution
\end_layout

\end_inset


\end_layout

\end_inset

 there are code, configurations and vagrant installer scripts.
 The installation instructions can be found in the readme.
 We used also promise pattern 
\begin_inset CommandInset citation
LatexCommand cite
key "PromiseJS"

\end_inset

 to make callbacks more readable.
\end_layout

\begin_layout Standard
We analyze quickly the structure of the code, of course everything is commented
 so we explain only the critical points.
\begin_inset Newline newline
\end_inset

Database, sample table, trigger with related functions, these are very simple
 and follow the structure.
 As we said previously the database is neither distributed nor partitioned.
\begin_inset Newline newline
\end_inset

Database listener is very simple and follows the structure previously explained.
 We insert it in a separated section because (as we have done in the vagrant
 installer scripts) it can be deployed on another machine (only one machine,
 in fact it cannot be distributed), of course it can be deployed in the
 same machine of the database.
\begin_inset Newline newline
\end_inset

This listener sends an event to clients of a specif room (we  analyze logic
 of rooms below) for every action done in the table (insert, update, delete)
 as socket.io event (the event name is the SQL action).
 As we said previously the table is specified as namespace.
\begin_inset Newline newline
\end_inset

Redis server does not require additional codes, so only vagrant installer
 script is provided.
\begin_inset Newline newline
\end_inset

Websocket server is explained below since it is very complex.
 It can be distributed using a load balance, but only the installer script
 of a single machine is provided (no load balancer script) since we do not
 want to test load balancer (that means another level to test).
\begin_inset Newline newline
\end_inset

Finally we quickly observe below what the client does.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Server-traditional"

\end_inset

Websocket server
\end_layout

\begin_layout Standard
The behavior is trivial, since much work is done automatically as we said
 previously, we recap briefly what we have done.
\begin_inset Newline newline
\end_inset

We define the same actions for all tables (specified in namespace via 
\begin_inset Quotes fld
\end_inset

of
\begin_inset Quotes frd
\end_inset

).
 
\begin_inset Newline newline
\end_inset

We define auth event callback that identifies the client.
\begin_inset Newline newline
\end_inset

We define join event callback that allows to a client to subscribe to rooms
 enabled for him.
 In this case we have provided a simple permission system where the room
 number is the owner_id of the row.When a client joins a room all rows of
 that room are sent to the client (initial retrieve): emulating the 
\begin_inset Quotes fld
\end_inset

insert
\begin_inset Quotes frd
\end_inset

 event created by the database listener after having done a read all for
 that room.
 Of course the number of rows can be limited.
\begin_inset Newline newline
\end_inset

We map client data events (add, put, delete) to SQL functions (insert, update,
 delete) making some checks.
 If there is an error (such as no permission) we discard the command and
 send the right command only to the client that has sent the request to
 update the local database of the client.
 For example if a client tries to add a row using an owner_id that is not
 enabled for him the server discards the add and sends a delete event to
 that client.
\end_layout

\begin_layout Standard
Using this approach, as said previously, the consistency of data modification
 is managed by postgreSQL and it is like any normal modern HTTP application,
 in fact data do not pass through redis in this phase.
\begin_inset Newline newline
\end_inset

The normal read is managed automatically and it is eventual consistency
 since the replication to local database is not synchronized but socket.io
 guarantees FIFO delivery.There is only one critical point: what if there
 is a change during the initial retrieve considering that the client is
 not able to distinguish data (initial retrieve or other events)? We could
 have different situations.
\begin_inset Newline newline
\end_inset

A notify event is called before the initial retrieve is executed.
 Updates and deletes are discarded since there is no data, insertions are
 added to local database but they cannot be newer than the data sent from
 the initial retrieve (for the same reason of the next point).
 Of course update/delete for rows added are considered.
 So it remains eventual consistency.
\begin_inset Newline newline
\end_inset

A notify event is called (and so the websocket event) before the operation
 is committed and so visible to the select done meantime (this  cause select
 data older than notify event sent previously).
 This is impossible since the notify is really called only after commit.
\begin_inset Newline newline
\end_inset

A notify event is called during the sending of initial data to the client.
 Since socket.io is executed in the same thread and delivery is FIFO, the
 sending of initial data is done before the new ones.
\begin_inset Newline newline
\end_inset

A notify change arrives before the answer of the select (but the select
 command was already sent).
 In this case we lose the change, but it is still eventual consistency.
 Of course improvements such as queue of events locked (until initial retrieve
 is finished) are good, but are not implemented to keep the simplicity of
 the code.
\begin_inset Newline newline
\end_inset

So if the events are fired before initial retrieve, they are not a problem
 since they are discarded or cause eventually consistency.
 At the same time if events are fired after initial retrieve, they are not
 a problem since they are caught (since there is FIFO guarantee).
 But events sent during initial retrieve are a problem since we can lose
 something due to the fact that we could discard them, of course we keep
 eventually consistency.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Client-traditional"

\end_inset

Client
\end_layout

\begin_layout Standard
We have two main classes: socket.io client, this class simply maps to socket.io
 commands functions and callbacks that local database wants and general
 local database.
\begin_inset Newline newline
\end_inset

The general local database has to do the following operations: keep a local
 copy of data, when a change is requested it updates local data then sends
 update to the server retrying to send it if there are network delays, when
 a notification of change is received it updates local data and calls a
 callback that says that data were updated and as explained previously it
 adds a UUID to each row created.
 Of course the final client interacts only with the local database.
\end_layout

\end_body
\end_document
